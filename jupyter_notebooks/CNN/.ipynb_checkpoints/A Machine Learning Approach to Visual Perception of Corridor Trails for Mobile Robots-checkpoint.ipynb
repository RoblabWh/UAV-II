{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Machine Learning Approach to Visual Perception of Corridor Trails for Mobile Robots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Author: Artur Leinweber <br>\n",
    "@E-Mail: arturleinweber@live.de <br>\n",
    "@University: Westphalian University of Gelsenkenkichen <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "tf.keras is TensorFlow's implementation of the Keras API specification. This is a high-level API to build and train models that includes first-class support for TensorFlow-specific functionality.\n",
    "Importing tf.keras makes TensorFlow easier to use without sacrificing flexibility and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers, utils, preprocessing, optimizers, backend\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "print(\"Tensorflow Version: \" + tf.VERSION)\n",
    "print(\"Keras Version: \" + tf.keras.__version__)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential model\n",
    "In Keras, you assemble layers to build models. A model is (usually) a graph of layers. The most common type of model is a stack of layers: the tf.keras.Sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "Conv2DLayer1 = layers.Conv2D(input_shape = (101,101,3),\n",
    "                             filters = 32,\n",
    "                             kernel_size = (4,4),\n",
    "                             padding = \"valid\",\n",
    "                             strides = (1, 1),\n",
    "                             kernel_initializer = \"glorot_uniform\",\n",
    "                             kernel_regularizer = regularizers.l2(0.0005)) \n",
    "\n",
    "ActivationLayer1 = layers.Activation(\"tanh\")\n",
    "\n",
    "NormalizationLayer1 = layers.BatchNormalization()\n",
    "\n",
    "PoolingLayer1 = layers.MaxPooling2D(pool_size = (2, 2),\n",
    "                                    strides = (2, 2),\n",
    "                                    padding = \"valid\")\n",
    "\n",
    "# Layer 2\n",
    "Conv2DLayer2 = layers.Conv2D(filters = 32,\n",
    "                             kernel_size = (4,4),\n",
    "                             padding = \"valid\",\n",
    "                             strides = (1, 1),\n",
    "                             kernel_initializer = \"glorot_uniform\",\n",
    "                             kernel_regularizer = regularizers.l2(0.0005))\n",
    "\n",
    "ActivationLayer2 = layers.Activation(\"tanh\")\n",
    "\n",
    "NormalizationLayer2 = layers.BatchNormalization()\n",
    "\n",
    "PoolingLayer2 = layers.MaxPooling2D(pool_size = (2, 2),\n",
    "                                    strides = (2, 2),\n",
    "                                    padding = \"valid\")\n",
    "# Layer 3\n",
    "Conv2DLayer3 = layers.Conv2D(filters = 32,\n",
    "                             kernel_size = (4,4),\n",
    "                             padding = \"valid\",\n",
    "                             strides = (1, 1),\n",
    "                             kernel_initializer = \"glorot_uniform\",\n",
    "                             kernel_regularizer = regularizers.l2(0.0005))\n",
    "\n",
    "ActivationLayer3 = layers.Activation(\"tanh\")\n",
    "\n",
    "NormalizationLayer3 = layers.BatchNormalization()\n",
    "\n",
    "PoolingLayer3 = layers.MaxPooling2D(pool_size = (2, 2),\n",
    "                                    strides = (2, 2),\n",
    "                                    padding = \"valid\")\n",
    "# Layer 4\n",
    "Conv2DLayer4 = layers.Conv2D(filters = 32,\n",
    "                             kernel_size = (3,3),\n",
    "                             padding = \"valid\",\n",
    "                             strides = (1, 1),\n",
    "                             kernel_initializer = \"glorot_uniform\",\n",
    "                             kernel_regularizer = regularizers.l2(0.0005))\n",
    "\n",
    "ActivationLayer4 = layers.Activation(\"tanh\")\n",
    "\n",
    "NormalizationLayer4 = layers.BatchNormalization()\n",
    "\n",
    "PoolingLayer4 = layers.MaxPooling2D(pool_size = (2, 2),\n",
    "                                    strides = (2, 2),\n",
    "                                    padding = \"valid\")\n",
    "# Fully Connected Layer\n",
    "FlattenLayer5 = layers.Flatten()\n",
    "DenseLayer5 = layers.Dense(200, kernel_initializer = \"glorot_uniform\")\n",
    "ActivationLayer5 = layers.Activation(\"tanh\")\n",
    "NormalizationLayer5 = layers.BatchNormalization()\n",
    "\n",
    "# Softmax Classifier\n",
    "DenseLayer6 = layers.Dense(3)\n",
    "ActivationLayer6 = layers.Activation(\"softmax\")\n",
    "\n",
    "model_architecture = [\n",
    "         Conv2DLayer1,\n",
    "         ActivationLayer1,\n",
    "         NormalizationLayer1,\n",
    "         PoolingLayer1,\n",
    "         \n",
    "         Conv2DLayer2,\n",
    "         ActivationLayer2,\n",
    "         NormalizationLayer2,\n",
    "         PoolingLayer2,\n",
    "         \n",
    "         Conv2DLayer3,\n",
    "         ActivationLayer3,\n",
    "         NormalizationLayer3,\n",
    "         PoolingLayer3,\n",
    "         \n",
    "         Conv2DLayer4,\n",
    "         ActivationLayer4,\n",
    "         NormalizationLayer4,\n",
    "         PoolingLayer4,\n",
    "         \n",
    "         FlattenLayer5,\n",
    "         DenseLayer5,\n",
    "         ActivationLayer5,\n",
    "         NormalizationLayer5,\n",
    "         \n",
    "         DenseLayer6,\n",
    "         ActivationLayer6]\n",
    "\n",
    "model = tf.keras.Sequential(model_architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prints a summary representation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a graph of the model and save it to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='plots/model.png')\n",
    "Image(retina=True, filename='plots/model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments for Training, that we need to set are:\n",
    "* The path to the input dataset.\n",
    "* The number of epochs to train for.\n",
    "* Path for Our loss/accuracy plot, that will be output to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.getcwd() + \"/dataset\"\n",
    "NUMBER_OF_EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_EVAL_PLOT_PATH = os.getcwd() + \"/plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the dataset structure:\n",
    "\n",
    "+ dataset\n",
    "    - left (X Files)\n",
    "    - forward (X Files)\n",
    "    - right (X Files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the set of labels from dataset we are going to train our network on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = set([\"left\", \"forward\", \"right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genrate a list of image pathes for our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images(DATASET_PATH))\n",
    "print(\"Size of the training dataset: \" + str(len(imagePaths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the list of images in our dataset directory, then initialize the list of data (i.e., images) and class images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    " \n",
    "    if label not in LABELS:\n",
    "        continue\n",
    " \n",
    "    image = cv2.imread(imagePath)\n",
    "    #image = imutils.resize(img, width=1280)\n",
    "    image = cv2.resize(image, (101, 101))\n",
    " \n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data into a NumPy array, then preprocess it by scaling all pixel intensities to the range (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating one-hot encoding vectors on the labels, for example: <br>\n",
    "(0,0,1) for \"left\" <br>\n",
    "(0,1,0) for \"forward\" <br>\n",
    "(1,0,0) for \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "hot_encoding_vectors = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the data into training and testing splits using 70% of the data for training and the remaining 30% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "                                                  hot_encoding_vectors,\n",
    "                                                  test_size=0.3,\n",
    "                                                  stratify=labels,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the training image generator for data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAugmentation = preprocessing.image.ImageDataGenerator(rotation_range=10,\n",
    "                                                          zoom_range=0.15,\n",
    "                                                          width_shift_range=0.2,\n",
    "                                                          height_shift_range=0.2,\n",
    "                                                          shear_range=0.15,\n",
    "                                                          horizontal_flip=False,\n",
    "                                                          vertical_flip=False,\n",
    "                                                          fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adamOptimizer = optimizers.Adam(lr=1e-4, decay=1e-4 / NUMBER_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is constructed, configure its learning process by calling the compile method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adamOptimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns whether TensorFlow can access a Nvidia GPU with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(cuda_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on data generated batch-by-batch by a Python generator (or an instance of Sequence).\n",
    "The generator is run in parallel to the model, for efficiency. For instance, this allows you to do real-time data augmentation on images on CPU in parallel to training your model on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "trainHistory = model.fit_generator(dataAugmentation.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
    "                                   validation_data=(testX, testY),\n",
    "                                   steps_per_epoch=len(trainX) // BATCH_SIZE,\n",
    "                                   epochs=NUMBER_OF_EPOCHS,\n",
    "                                   verbose=2)\n",
    "\n",
    "end_time = time. time()\n",
    "print(\"Total training time: \" + str(end_time - start_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A History.history attribute saves a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "To evaluate our model, weâ€™ll use the testX  data and print a classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testX, batch_size=BATCH_SIZE)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                            predictions.argmax(axis=1),\n",
    "                            target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot our accuracy/loss training history and save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = NUMBER_OF_EPOCHS\n",
    "H = trainHistory\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(TRAIN_EVAL_PLOT_PATH + \"/Loss_Accuracy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save weights only (TensorFlow checkpoint file or Keras HDF5 format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/weights.ckpt')\n",
    "model.save_weights('./weights/weights.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save configuration only (JSON or YAML format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "\n",
    "json_string = model.to_json()\n",
    "yaml_string = model.to_yaml()\n",
    "\n",
    "with open('./config/data.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)\n",
    "    \n",
    "with open('./config/data.yml', 'w') as outfile:\n",
    "    yaml.dump(yaml_string, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save entire model (HDF5 file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "- https://www.tensorflow.org/guide/keras\n",
    "- http://rpg.ifi.uzh.ch/docs/RAL16_Giusti.pdf\n",
    "- https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/\n",
    "- https://keras.io/models/sequential/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
